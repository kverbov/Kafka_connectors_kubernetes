apiVersion: v1
kind: ConfigMap
metadata:
  name: source-hive-dmemployeebranchactual
  namespace: dbzm-prod
binaryData:
  rrsdbo.keytab: 
data:
  source-hive-dmemployeebranchactual.connector.config.json: |-
    {
      "name": "source-hive-dmemployeebranchactual",
      "config": {
          "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
          "connection.url": "jdbc:hive2://rrr-aspmosmdp02.bank.rrr.department:10000/hist_gp_etl;AuthMech=1;principal=servername;Kservername.bank.rrr.department",
          "db.timezone": "UTC",
          "table.types": "VIEW",
          "schema.pattern": "hist_gp_etl",
          "table.whitelist": "dm_employee_branch_actual",
          "mode": "timestamp",
          "timestamp.column.name": "updated",
          "numeric.mapping": "best_fit",
          "topic.prefix": "odpp.prod.cdc.",
          "validate.non.null": "false",
          "poll.interval.ms": "192.168.1.2",
          "producer.sasl.kerreros.service.name" : "hive",
          "transforms": "AddPrefix",
          "transforms.AddPrefix.type": "org.apache.kafka.connect.transforms.RegexRouter",
          "transforms.AddPrefix.regex": "(.+)",
          "transforms.AddPrefix.replacement": "odpp.prod.cdc.dmemployeebranchactual"
      }
    }

  krr5.conf: |-
    [libdefaults]
      renew_lifetime = 7d
      forwardable = true
      default_realm = bank.rrr.department
      ticket_lifetime = 24h
      dns_lookup_realm = false
      dns_lookup_kdc = false
      default_ccache_name = /tmp/krr5cc_%{uid}

    [domain_realm]
      .bank.rrr.department = bank.rrr.department
      bank.rrr.department = bank.rrr.department

    [realms]
      bank.rrr.department = {
        admin_server = bank.rrr.department
        kdc = bank.rrr.department
      }
      
  kafka_jaas.conf: |-
   Client {
   com.sun.security.auth.module.Krr5LoginModule required
   useKeyTab=true
   storeKey=true
   renewTGT=true
   useTicketCache=true
   keyTab="/kafka/mounted/rrsdbo.keytab"
   principal="rrsdbo@bank.rrr.department";
   };

  .envs: |-
    #{ Dynamic (custom for each connector)
    CONFIG_STORAGE_TOPIC="odpp.prod.cdct.dmemployeebranchactual.configs"
    OFFSET_STORAGE_TOPIC="odpp.prod.cdct.dmemployeebranchactual.offsets"
    STATUS_STORAGE_TOPIC="odpp.prod.cdct.dmemployeebranchactual.statuses"
    GROUP_ID=source-dmemployeebranchactual
    OFFSET_FLUSH_INTERVAL_MS=1200
    OFFSET_FLUSH_TIMEOUT_MS=2500
    SHUTDOWN_TIMEOUT=2000
    KAFKA_OPTS="
    -Dsun.security.krr5.debug=false
    -Djava.security.kservername.conf
    -Djava.security.auth.login.config=/kafka/mounted/kafka_jaas.conf
    -Djavax.security.auth.useSubjectCredsOnly=false"
    #}

    #{ Static (rarely changed)
      #{ Common part
    REST_HOST_NAME="192.168.1.2"
    ADVERTISED_HOST_NAME="192.168.1.2"
    CONNECT_OFFSET_STORAGE_PARTITIONS=1
    CONNECT_CONFIG_STORAGE_PARTITIONS=1
    CONNECT_STATUS_STORAGE_PARTITIONS=1
    CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=-1
    CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=-1
    CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=-1
    CONNECT_OFFSET_STORAGE_CLEANUP_POLICY="compact"
    CONNECT_CONFIG_STORAGE_CLEANUP_POLICY="compact"
    CONNECT_STATUS_STORAGE_CLEANUP_POLICY="compact"
      #}

      #{ for retail cluster of Kafka
    BOOTSTRAP_SERVERS="servername.domain.department:9093,servername"
    CONNECT_SECURITY_PROTOCOL="SSL"
    CONNECT_CONSUMER_SECURITY_PROTOCOL="SSL"
    CONNECT_PRODUCER_SECURITY_PROTOCOL="SSL"
    CONNECT_SSL_.rrrTSTORE_LOCATION="/kafka/.ssl/kafka.retail.prod..rrrtstore.jks"
    CONNECT_PRODUCER_SSL_.rrrTSTORE_LOCATION="/kafka/.ssl/kafka.retail.prod..rrrtstore.jks"
    CONNECT_CONSUMER_SSL_.rrrTSTORE_LOCATION="/kafka/.ssl/kafka.retail.prod..rrrtstore.jks"
    CONNECT_SSL_.rrrTSTORE_PASSWORD="password"
    CONNECT_PRODUCER_SSL_.rrrTSTORE_PASSWORD="password"
    CONNECT_CONSUMER_SSL_.rrrTSTORE_PASSWORD="password"
      #}
    #}

  # only for extra properties that are not in base image's /kafka/config.orig/connect-distributed.properties file
  extra.connect-distributed.properties: |
    # nothing extra (yet)

  log4j.properties: |-
    log4j.rootLogger=INFO, console, gelf

    # Disable excessive reflection warnings - KAFKA-5229
    log4j.logger.org.reflections=ERROR

    log4j.appender.console=org.apache.log4j.ConsoleAppender
    log4j.appender.console.threshold=INFO
    log4j.appender.console.layout=org.apache.log4j.PatternLayout
    log4j.appender.console.layout.ConversionPattern=%d{ISO8601} %-5p  %X{dbz.connectorType}|%X{dbz.connectorName}|%X{dbz.connectorContext}  %m   [%c]%n

    log4j.appender.gelf=biz.paluch.logging.gelf.log4j.GelfLogAppender
    log4j.appender.gelf.Threshold=WARN
    log4j.appender.gelf.Host=udp:mbr-log.bank.rrr.department
    log4j.appender.gelf.Port=12201
    log4j.appender.gelf.Version=1.1
    log4j.appender.gelf.Facility=logstash-gelf
    log4j.appender.gelf.ExtractStackTrace=true
    log4j.appender.gelf.FilterStackTrace=true
    log4j.appender.gelf.MdcProfiling=true
    log4j.appender.gelf.IncludeFullMdc=true
    log4j.appender.gelf.AdditionalFields=namespace=dbzm-prod
    log4j.appender.gelf.TimestampPattern=yyyy-MM-dd'T'HH:mm:ss.SSS

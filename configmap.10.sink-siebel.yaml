apiVersion: v1
kind: ConfigMap
metadata:
  name: sink-siebel
  namespace: dbzm-prod
data:
  sink-siebel.dboevo.device.connector.config.json: |-
    {
       "name": "prod.siebel.dboevo.device",
       "config": {
          "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
          "connection.url": "jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=DBNRTPROD.bank.rrr.department)(PORT=1525))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=SBNRT_PRIMARY)))",
          "connection.user": "user",
          "connection.password": "password",
          "topics": "rdbo.prod.cdc.uprf.device",
          "table.name.format": "DEVICE",
          "transforms": "unwrap,convert",
          "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
          "transforms.unwrap.drop.tombstones": "false",
          "transforms.convert.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
          "transforms.convert.target.type": "Timestamp",
          "transforms.convert.format": "yyyy-MM-dd HH:mm:ss",
          "transforms.convert.field": "created,blockdate",
          "auto.create": "false",
          "auto.evolve": "false",
          "insert.mode": "upsert",
          "delete.enabled": "true",
          "pk.fields": "id",
          "pk.mode": "record_key",
          "quote.sql.identifiers": "never"
       }
    }

  sink-siebel.dboevo.session_event.connector.config.json: |-
    {
       "name": "prod.siebel.dboevo.session_event",
       "config": {
          "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
          "connection.url": "jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=DBNRTPROD.bank.rrr.department)(PORT=1525))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=SBNRT_PRIMARY)))",
          "connection.user": "user",
          "connection.password": "password",
          "topics": "rdbo.prod.cdc.uprf.sessionevent",
          "table.name.format": "SESSION_EVENT",
          "transforms": "unwrap,convert",
          "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
          "transforms.unwrap.drop.tombstones": "false",
          "transforms.convert.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
          "transforms.convert.target.type": "Timestamp",
          "transforms.convert.format": "yyyy-MM-dd HH:mm:ss",
          "transforms.convert.field": "created,expiry,finished,blockdate",
          "auto.create": "false",
          "auto.evolve": "false",
          "insert.mode": "upsert",
          "delete.enabled": "true",
          "pk.fields": "id",
          "pk.mode": "record_key",
          "quote.sql.identifiers": "never"
       }
    }

  sink-siebel.dboevo.user_record.connector.config.json: |-
    {
       "name": "prod.siebel.dboevo.user_record",
       "config": {
          "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
          "connection.url": "jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=DBNRTPROD.bank.rrr.department)(PORT=1525))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=SBNRT_PRIMARY)))",
          "connection.user": "user",
          "connection.password": "password",
          "topics": "rdbo.prod.cdc.uprf.userrecord",
          "table.name.format": "USER_RECORD",
          "transforms": "unwrap,convert",
          "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
          "transforms.unwrap.drop.tombstones": "false",
          "transforms.convert.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
          "transforms.convert.target.type": "Timestamp",
          "transforms.convert.format": "yyyy-MM-dd HH:mm:ss",
          "transforms.convert.field": "sessionexpiry,sessionfinish,created,updated",
          "auto.create": "false",
          "auto.evolve": "false",
          "insert.mode": "upsert",
          "delete.enabled": "true",
          "pk.fields": "userid",
          "pk.mode": "record_key",
          "quote.sql.identifiers": "never"
       }
    }
    
  sink-siebel.siebel.cx_order_limit.connector.config.json: |-
    {
       "name": "prod.siebel.siebel.cx_order_limit",
       "config": {
          "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
          "connection.url": "jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=DBNRTPROD.bank.rrr.department)(PORT=1525))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=SBNRT_PRIMARY)))",
          "connection.user": "user",
          "connection.password": "password",
          "topics": "rdbo.prod.cdc.lmts.client_banklimits",
          "table.name.format": "SIEBEL.CX_ORDER_LIMIT",
          "transforms": "unwrap,convert",
          "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
          "transforms.unwrap.drop.tombstones": "true",
          "transforms.convert.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
          "transforms.convert.target.type": "Timestamp",
          "transforms.convert.format": "yyyy-MM-dd HH:mm:ss",
          "transforms.convert.field": "start_date,end_date",
          "auto.create": "false",
          "auto.evolve": "false",
          "insert.mode": "upsert",
          "delete.enabled": "false",
          "fields.whitelist": "id, customer_id, channel, operation_type, currency, limit_value, start_date, end_date",
          "pk.fields": "id",
          "pk.mode": "record_key",
          "quote.sql.identifiers": "never"
       }
    }

  sink-siebel.dboevo.cx_dbo_chan_cnt.connector.config.json: |-
    {
       "name": "prod.siebel.dboevo.cx_dbo_chan_cnt",
       "config": {
          "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
          "connection.url": "jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=DBNRTPROD.bank.rrr.department)(PORT=1525))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=SBNRT_PRIMARY)))",
          "connection.user": "user",
          "connection.password": "password",
          "topics": "siebel.prod.clientactuality.event.v1",
          "table.name.format": "SIEBEL.CX_DBO_CHAN_CNT",
          "transforms": "unwrap,convert",
          "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
          "transforms.unwrap.drop.tombstones": "true",
          "transforms.convert.type": "org.apache.kafka.connect.transforms.TimestampConverter$Value",
          "transforms.convert.target.type": "Timestamp",
          "transforms.convert.format": "yyyy-MM-dd HH:mm:ss",
          "transforms.convert.field": "CREATE_DATE",
          "auto.create": "false",
          "auto.evolve": "false",
          "insert.mode": "upsert",
          "delete.enabled": "false",
          "fields.whitelist": "CUSTOMER_ID, DBO_ID, ID, CREATE_DATE, CHANNEL_TYPE, OPERATION_TYPE, VALUE_TO_CHANGE",
          "pk.fields": "ID",
          "pk.mode": "record_key",
          "quote.sql.identifiers": "never"
       }
    }

  .envs: |-
    #{ Dynamic (custom for each connector)
    CONFIG_STORAGE_TOPIC="rdbo.prod.cdct.sink.configs.siebel"
    OFFSET_STORAGE_TOPIC="rdbo.prod.cdct.dummy"
    STATUS_STORAGE_TOPIC="rdbo.prod.cdct.sink.statuses.siebel"
    GROUP_ID=10
    OFFSET_FLUSH_INTERVAL_MS=1200
    OFFSET_FLUSH_TIMEOUT_MS=5000
    SHUTDOWN_TIMEOUT=2000
    #}

    #{ Static (rarely changed)
      #{ Common part
    REST_HOST_NAME="192.168.1.2"
    ADVERTISED_HOST_NAME="192.168.1.2"
    CONNECT_OFFSET_STORAGE_PARTITIONS=1
    CONNECT_CONFIG_STORAGE_PARTITIONS=1
    CONNECT_STATUS_STORAGE_PARTITIONS=1
    CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=-1
    CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=-1
    CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=-1
    CONNECT_OFFSET_STORAGE_CLEANUP_POLICY="compact"
    CONNECT_CONFIG_STORAGE_CLEANUP_POLICY="compact"
    CONNECT_STATUS_STORAGE_CLEANUP_POLICY="compact"
      #}

      #{ for retail cluster of Kafka
    BOOTSTRAP_SERVERS="servername.domain.department:9093,servername"
    CONNECT_SECURITY_PROTOCOL="SSL"
    CONNECT_CONSUMER_SECURITY_PROTOCOL="SSL"
    CONNECT_PRODUCER_SECURITY_PROTOCOL="SSL"
    CONNECT_SSL_.rrrTSTORE_LOCATION="/kafka/.ssl/kafka.retail.prod..rrrtstore.jks"
    CONNECT_PRODUCER_SSL_.rrrTSTORE_LOCATION="/kafka/.ssl/kafka.retail.prod..rrrtstore.jks"
    CONNECT_CONSUMER_SSL_.rrrTSTORE_LOCATION="/kafka/.ssl/kafka.retail.prod..rrrtstore.jks"
    CONNECT_SSL_.rrrTSTORE_PASSWORD="password"
    CONNECT_PRODUCER_SSL_.rrrTSTORE_PASSWORD="password"
    CONNECT_CONSUMER_SSL_.rrrTSTORE_PASSWORD="password"
      #}
    #}

  # only for extra properties that are not in base image's /kafka/config.orig/connect-distributed.properties file
  extra.connect-distributed.properties: |
    # nothing extra (yet)

  log4j.properties: |-
    log4j.rootLogger=INFO, console, gelf

    # Disable excessive reflection warnings - KAFKA-5229
    log4j.logger.org.reflections=ERROR

    log4j.appender.console=org.apache.log4j.ConsoleAppender
    log4j.appender.console.threshold=INFO
    log4j.appender.console.layout=org.apache.log4j.PatternLayout
    log4j.appender.console.layout.ConversionPattern=%d{ISO8601} %-5p  %X{dbz.connectorType}|%X{dbz.connectorName}|%X{dbz.connectorContext}  %m   [%c]%n

    log4j.appender.gelf=biz.paluch.logging.gelf.log4j.GelfLogAppender
    log4j.appender.gelf.Threshold=WARN
    log4j.appender.gelf.Host=udp:mbr-log.bank.rrr.department
    log4j.appender.gelf.Port=12201
    log4j.appender.gelf.Version=1.1
    log4j.appender.gelf.Facility=logstash-gelf
    log4j.appender.gelf.ExtractStackTrace=true
    log4j.appender.gelf.FilterStackTrace=true
    log4j.appender.gelf.MdcProfiling=true
    log4j.appender.gelf.IncludeFullMdc=true
    log4j.appender.gelf.AdditionalFields=namespace=dbzm-prod
    log4j.appender.gelf.TimestampPattern=yyyy-MM-dd'T'HH:mm:ss.SSS
